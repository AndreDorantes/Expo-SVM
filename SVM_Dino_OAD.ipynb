{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning\n",
        "\n",
        "# Task: Supervised Learning - SVM\n",
        "\n",
        "# Oscar Andre Dorantes Victor\n",
        "\n",
        "# IRC 9B\n",
        "\n",
        "# 10/30/2023"
      ],
      "metadata": {
        "id": "EYmjUG8T8Xoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "DQZJFpH8REEA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/kaggledino.csv\")\n",
        "\n",
        "#Remove rows with missing 'Diet'\n",
        "data = data.dropna(subset=['Diet'])\n",
        "\n",
        "#Label encode categorical columns\n",
        "label_encoders = {}\n",
        "for column in ['What Dinosaurs Eat', 'Country', 'Geological Time Period']:\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column])"
      ],
      "metadata": {
        "id": "ETd7SaxRRFFv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Load the Dataset: The read_csv function from the pandas library is used to load the dataset from the provided path into a DataFrame called data.\n",
        "\n",
        "2.   Remove Missing Values: The dropna function removes rows where the 'Diet' column has missing values. This ensures that the data used for modeling is complete.\n",
        "\n",
        "3.   Label Encoding: This section encodes categorical columns into numerical values, making them suitable for machine learning algorithms. The columns 'What Dinosaurs Eat', 'Country', and 'Geological Time Period' are transformed. A dictionary (label_encoders) is initialized to potentially store these encoders for later use, but it's not used in the provided code.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GRriJHCVGOXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define features and target\n",
        "features = ['Lat', 'Lng', 'What Dinosaurs Eat', 'Country', 'Geological Time Period', 'Max Ma', 'Min Ma']\n",
        "X = data[features]\n",
        "y = data['Diet']\n",
        "\n",
        "#Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Z26Bl6IrRSMu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Define Features and Target: The features (input variables) and the target (output variable) for the machine learning model are defined. The columns specified in the features list are used as input features, and the 'Diet' column is the target variable.\n",
        "\n",
        "2.   Data Splitting: The train_test_split function divides the dataset into training and testing sets. 80% of the data is used for training, and the remaining 20% is reserved for testing.\n",
        "\n",
        "3. Feature Standardization: The features are standardized (zero mean and unit variance) using the StandardScaler. This step is essential for algorithms like SVM that are sensitive to the scale of input features.\n",
        "\n"
      ],
      "metadata": {
        "id": "GCySXOx4Gljj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize and train SVM with RBF kernel\n",
        "svm_classifier_rbf = SVC(kernel='rbf', C=1)\n",
        "svm_classifier_rbf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "YozaklWGRUDI",
        "outputId": "0aee259b-a04e-476b-f8d1-d5f9ccd04bc4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   SVM Initialization: An SVM classifier with a Radial Basis Function (RBF) kernel is initialized. The regularization parameter C is set to 1.\n",
        "\n",
        "2.   Training: The classifier is trained using the standardized training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "rjZ1_TwiGu_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on test data\n",
        "y_pred_rbf = svm_classifier_rbf.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "YTg2cJ10RV7F"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Using the trained SVM classifier, predictions are made on the standardized test data. The predictions are stored in y_pred_rbf.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b7-kbMk6G5LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display results\n",
        "def display_results(y_true, y_pred):\n",
        "    report = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
        "\n",
        "    print(\"Classification Results:\\n\")\n",
        "    for label, metrics in report.items():\n",
        "        if label in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "            continue\n",
        "        print(f\"Class: {label}\")\n",
        "        print(f\"  - Precision (True Positives / (True Positives + False Positives)): {metrics['precision']:.2f}\")\n",
        "        print(f\"  - Recall (True Positives / (True Positives + False Negatives)): {metrics['recall']:.2f}\")\n",
        "        print(f\"  - F1-Score (Harmonic Mean of Precision and Recall): {metrics['f1-score']:.2f}\")\n",
        "        print(f\"  - Support (Number of actual occurrences of the class): {metrics['support']}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(f\"Overall Accuracy (Correct Predictions / Total Predictions): {report['accuracy']:.2f}\")\n",
        "\n",
        "# Display results\n",
        "display_results(y_test, y_pred_rbf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZBnzrtk-zo9",
        "outputId": "30d6b970-61b9-4b2e-8241-2b1daaad6e4d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Results:\n",
            "\n",
            "Class: carnivore\n",
            "  - Precision (True Positives / (True Positives + False Positives)): 1.00\n",
            "  - Recall (True Positives / (True Positives + False Negatives)): 1.00\n",
            "  - F1-Score (Harmonic Mean of Precision and Recall): 1.00\n",
            "  - Support (Number of actual occurrences of the class): 212\n",
            "\n",
            "\n",
            "Class: carnivore, omnivore\n",
            "  - Precision (True Positives / (True Positives + False Positives)): 0.57\n",
            "  - Recall (True Positives / (True Positives + False Negatives)): 0.81\n",
            "  - F1-Score (Harmonic Mean of Precision and Recall): 0.67\n",
            "  - Support (Number of actual occurrences of the class): 16\n",
            "\n",
            "\n",
            "Class: herbivore\n",
            "  - Precision (True Positives / (True Positives + False Positives)): 1.00\n",
            "  - Recall (True Positives / (True Positives + False Negatives)): 1.00\n",
            "  - F1-Score (Harmonic Mean of Precision and Recall): 1.00\n",
            "  - Support (Number of actual occurrences of the class): 243\n",
            "\n",
            "\n",
            "Class: herbivore, omnivore\n",
            "  - Precision (True Positives / (True Positives + False Positives)): 0.00\n",
            "  - Recall (True Positives / (True Positives + False Negatives)): 0.00\n",
            "  - F1-Score (Harmonic Mean of Precision and Recall): 0.00\n",
            "  - Support (Number of actual occurrences of the class): 5\n",
            "\n",
            "\n",
            "Class: omnivore\n",
            "  - Precision (True Positives / (True Positives + False Positives)): 0.43\n",
            "  - Recall (True Positives / (True Positives + False Negatives)): 0.33\n",
            "  - F1-Score (Harmonic Mean of Precision and Recall): 0.38\n",
            "  - Support (Number of actual occurrences of the class): 9\n",
            "\n",
            "\n",
            "Class: piscivore\n",
            "  - Precision (True Positives / (True Positives + False Positives)): 1.00\n",
            "  - Recall (True Positives / (True Positives + False Negatives)): 1.00\n",
            "  - F1-Score (Harmonic Mean of Precision and Recall): 1.00\n",
            "  - Support (Number of actual occurrences of the class): 8\n",
            "\n",
            "\n",
            "Overall Accuracy (Correct Predictions / Total Predictions): 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Function Definition: The display_results function is defined to take in true labels (y_true) and predicted labels (y_pred). It computes various classification metrics like precision, recall, F1-score, and support using the classification_report function.\n",
        "\n",
        "2.   Displaying Metrics: The function is then called with the true test labels and the predicted labels to display the classification results. The metrics are printed in a formatted manner for each class in the dataset, followed by the overall accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "LhS47DUmHDSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Explanation:**\n",
        "\n",
        "\n",
        "*   Accuracy: This is the ratio of the number of correct predictions to the total number of predictions. In my case, it's 97.46%, which means the model correctly predicted the diet of the dinosaur for 97.46% of the test samples.\n",
        "\n",
        "*   Precision (for a class): It's the ratio of true positive predictions to the sum of true positive and false positive predictions for that class. In simpler words, out of all the samples that the model predicted to be of a certain class, how many were actually of that class?\n",
        "\n",
        "*   Recall (for a class): It's the ratio of true positive predictions to the sum of true positive and false negative predictions for that class. Essentially, out of all the samples that were actually of a certain class, how many did the model correctly predict?\n",
        "\n",
        "*   F1-score (for a class): It's the harmonic mean of precision and recall and gives a balance between the two. If either precision or recall is low for a class, the F1-score will also be low.\n",
        "\n",
        "*   Support: It's the number of actual occurrences of the class in the dataset.\n",
        "\n",
        "*   Macro avg: This is the average of the metrics for each class without considering class imbalance.\n",
        "\n",
        "*   Weighted avg: This is the average of the metrics for each class, weighted by the number of samples in each class.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_-ehmUPoHSSq"
      }
    }
  ]
}